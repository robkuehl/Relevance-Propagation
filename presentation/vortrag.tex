\documentclass[t, compress]{beamer}
% Defines
\def\CC{{\mathcal{C}}}
% Packages
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{caption}
%\usepackage{natbib}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{subfig}

\usepackage{bibentry}
%\usepackage{biblatex}
%\nobibliography*


\usepackage{filecontents}


%Fuelle bibtex mit Inhalt
\begin{filecontents}{meinebib.bib}
% Alexander Binder et al, 2016
@InProceedings{binder,
author="Binder, Alexander
and Bach, Sebastian
and Montavon, Gregoire
and M{\"u}ller, Klaus-Robert
and Samek, Wojciech",
editor="Kim, Kuinam J.
and Joukov, Nikolai",
title="Layer-Wise Relevance Propagation for Deep Neural Network Architectures",
booktitle="Information Science and Applications (ICISA) 2016",
year="2016",
publisher="Springer Singapore",
address="Singapore",
pages="913--922",
abstract="We present the application of layer-wise relevance propagation to several deep neural networks such as the BVLC reference neural net and googlenet trained on ImageNet and MIT Places datasets. Layer-wise relevance propagation is a method to compute scores for image pixels and image regions denoting the impact of the particular image region on the prediction of the classifier for one particular test image. We demonstrate the impact of different parameter settings on the resulting explanation.",
isbn="978-981-10-0557-2"
}

% Sebastian Bach et al, 2015 (ausfuehrlich!)
@article{bach,
    author = {Bach, Sebastian AND Binder, Alexander AND Montavon, Grégoire AND Klauschen, Frederick AND Müller, Klaus-Robert AND Samek, Wojciech},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
    year = {2015},
    month = {07},
    volume = {10},
    url = {https://doi.org/10.1371/journal.pone.0130140},
    pages = {1-46},
    abstract = {Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
    number = {7},
    doi = {10.1371/journal.pone.0130140}
}


% Gregoire Montavon et al, 2017 -> Deep Taylor Decomp.
@article{montavon,
title = "Explaining nonlinear classification decisions with deep Taylor decomposition",
journal = "Pattern Recognition",
volume = "65",
pages = "211 - 222",
year = "2017",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2016.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0031320316303582",
author = "Grégoire Montavon and Sebastian Lapuschkin and Alexander Binder and Wojciech Samek and Klaus-Robert Müller",
keywords = "Deep neural networks, Heatmapping, Taylor decomposition, Relevance propagation, Image recognition",
abstract = "Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets."
}

% David Baehrens et al, noch nicht verwendet
@article{baehrens,
  author  = {David Baehrens and Timon Schroeter and Stefan Harmeling and Motoaki Kawanabe and Katja Hansen and Klaus-Robert M{{\"u}}ller},
  title   = {How to Explain Individual Classification Decisions},
  journal = {Journal of Machine Learning Research},
  year    = {2010},
  volume  = {11},
  number  = {61},
  pages   = {1803-1831},
  url     = {http://jmlr.org/papers/v11/baehrens10a.html}
}

\end{filecontents}



%Eigene Befehle:

\newcommand{\rn}{\mathbb{R}}
% Die Beamervorlage einbinden
\input{beamersettings}

% Zum debuggen nuetzlich: Erzeugt ein Gitter im Hintergrund
%\setbeamertemplate{background}[grid][step=0.5cm]

% Navigationssymbole ausblenden
\setbeamertemplate{navigation symbols}{}

% Metadaten
\title{Relevance Propagation for Deep Neural Networks}
\subtitle{Zwischenvortrag 2}
\author{Theo Conrads, Robin K\"uhling, Marc Bremser}
\date{\today}
\titlegraphic{\includegraphics[width=5cm]{grafiken/rel_prop_vis.png}}

% Der eigentliche Vortrag  
\begin{document}

%\include{content_lrp}
\section{Implementierung LRP}
\frame{\frametitle{LRP für CNNs}
\begin{itemize}
\item Basisformel
\begin{align*}
R_{i}^{(l)}=\sum_{j} \frac{z_{i j}}{\sum_{i^{\prime}} z_{i^{\prime} j}} R_{j}^{(l+1)} \quad \text { mit } \quad \mathrm{z}_{\mathrm{ij}}=\mathrm{x}_{\mathrm{i}}^{(1)} \mathrm{w}_{\mathrm{ij}}^{(l,l+1)}
\end{align*}

\item Problematisch bei komplexeren Layern (\textit{Beispiel: ConvLayer})
\item Betrachte alternative Implementierung

\end{itemize}
}

\frame{\frametitle{LRP für CNNs}
\begin{itemize}
\item Basisformel
\begin{align*}
\begin{array}{ll}
\forall_{k}: z_{k}=\epsilon+\sum_{0, j} a_{j} \cdot \rho\left(w_{j k}\right) & \text { (forward pass) } \\
\forall_{k}: s_{k}=R_{k} / z_{k} & \text { (element-wise division) } \\
\forall_{j}: c_{j}=\sum_{k} \rho\left(w_{j k}\right) \cdot s_{k} & \text { (backward pass) } \\
\forall_{j}: R_{j}=a_{j} c_{j} & \text { (element-wise product) }
\end{array}
\end{align*}

\item Problematisch bei komplexeren Layern (\textit{Beispiel: ConvLayer})
\item Betrachte alternative Implementierung

\end{itemize}
}
\end{document}